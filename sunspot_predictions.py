from astropy.coordinates import SkyCoord
from sunpy.coordinates import frames
import astropy.units as u
import sklearn.cluster as cls
import numpy as np
import random as rand
import itime as itm
import copy
import warnings


class SunspotState:
    """

    stores data describing sunspot's features on one exact day (one observation)
    """

    def __init__(self, **kw):
        """

        :param kw:

        - time is a time of observation (itm.Time class exemplar)
        - wh_area is sunspot's whole area (float)
        - carrington is sunspot's Heliographic Carrington coordinates (SkyCoord class exemplar) (float)
        - stonyhurst is sunspot's Heliographic Stonyhurst coordinates (SkyCoord class exemplar) (float)
          if not specified, will be calculated from stonyhurst coordinates
        - lat is sunspot's latitude (float)
        - simulated is True if the state was generated by the algorithm and False otherwise
        - id is sunspot's identifier (string)
        """
        self.time = kw.pop('time') if 'time' in kw else itm.Time(str='0000 0 0.000')  # time of observation
        self.wh_area = kw.pop('wh_area') if 'wh_area' in kw else 0  # sunspot's whole area
        self.carrington = kw.pop('carrington') if 'carrington' in kw else None
        self.stonyhurst = kw.pop('stonyhurst') if 'stonyhurst' in kw else None
        self.lat = kw.pop('lat') if 'lat' in kw else 0
        self.simulated = kw.pop('simulated') if 'simulated' in kw else False
        self.id = kw.pop('spot_id') if 'spot_id' in kw else '0'
        if self.carrington is not None and self.stonyhurst is None:
            coord = SkyCoord(lon=self.carrington * u.deg,
                             lat=self.lat * u.deg,
                             frame='heliographic_carrington',
                             obstime=self.time.date())
            self.stonyhurst = (coord.transform_to(frames.HeliographicStonyhurst)).lon.degree

    def __str__(self):
        """

        :return: string representation of SunspotState
        """
        result = str(self.time)
        result += '% 10s' % self.id
        if self.simulated:
            result += ' 1'
        else:
            result += ' 0'
        result += '% 5d' % int(self.wh_area)
        result += '% 6.1f' % self.carrington
        result += '% 6.1f' % self.lat
        result += '% 6.1f' % self.stonyhurst
        return result

    def write(self, file):
        """

        writes sunspot state to the file
        :param file: file to write to
        """
        data_list = [str(self.time).replace(' ', '_'), str(int(self.wh_area)), str(self.carrington),
                     str(self.lat), str(self.stonyhurst)]
        file.write(' '.join(data_list) + '\n')


max_time_gap = 30  # max allowed time for sunspot to stay unobserved (if exceeded SunspotState is not considered)


class Sunspot:
    """

    stores full sunspot history
    """

    def __init__(self, spot_id):
        """

        :param spot_id: sunspot identifier
        """
        self.id = spot_id  # string-id of the sunspot
        self.states = list()  # stores exemplars of SunspotState class
        self.lifetime = 0  # number of days sunspot was observed

    def add_state(self, state):
        """

        adds new state to sunspot's history
        :param state: valid Sunspot state
        """
        if self.lifetime == 0:
            self.lifetime = 1
            self.states.append(state)
        else:
            time_gap = state.time - self.states[self.lifetime - 1].time
            if time_gap > max_time_gap:
                return
            self.states += [None] * time_gap
            self.lifetime += time_gap
            self.states[self.lifetime - 1] = state

    def write(self, file):
        """

        writes full sunspot history to the file
        :param file: a file to write to
        """
        file.write('#' + self.id + '\n')
        for state in self.states:
            if state is not None:
                state.write(file)


def process_line(spots, line):
    """

    parses line and creates new SunspotState
    :param spots: a dict of spots (mapping spot_id => Sunspot)
    :param line: a line to process
    :return: year of current spot (necessary for state printing)
    """
    spot_id = line[12:22].replace(' ', '')
    time = itm.Time(str=line[0:12])
    if spot_id != '0':
        spots.setdefault(spot_id, Sunspot(spot_id))
        spots[spot_id].add_state(SunspotState(time=time, wh_area=float(line[40:44]),
                                              carrington=float(line[57:62]), lat=float(line[63:68]), spot_id=spot_id))
    return time.year()


def process_data(filename, **kw):
    """

    :param filename: a file to process
    :param kw:

    - init_year: a year to start from (default: from the beginning of the database)
    - last_year: a year to finish (default: to the end of the database)
    - print_state: if True prints processing state (default: False)

    :return: a dict of spots (mapping spot_id => Sunspot)
    """
    warnings.filterwarnings('ignore')
    spots = dict()
    file = open(filename, 'r')
    init_year = kw.pop('init_year') if 'init_year' in kw else None
    last_year = kw.pop('last_year') if 'last_year' in kw else None
    print_state = kw.pop('print_state') if 'print_state' in kw else False
    year = None
    for line in file:
        if year is None:
            year = int(line[0:4])
            print(year)
        if init_year is not None and year < init_year:
            continue
        if last_year is not None and year > last_year:
            continue
        if year != int(line[0:4]) and print_state:
            print(year + 1)
        year = process_line(spots, line)
    file.close()
    return spots


def rewrite_database(spots, filename):
    """

    rewrites database to be reloaded faster
    :param spots: a dict of spots (mapping spot_id => Sunspot)
    :param filename: a file to store rewritten database
    """
    file = open(filename, 'w')
    for spot in spots.values():
        spot.write(file)
    file.close()


def scan_database(filename):
    """

    scans rewritten database
    :param filename: a file to scan rewritten database
    :return: a dict of spots (mapping spot_id => Sunspot)
    """
    file = open(filename, 'r')
    spots = dict()
    spot_id = None
    for line in file:
        if line == '':
            break
        if line[0] == '#':
            spot_id = line[1:-1]
            spots.setdefault(spot_id, Sunspot(spot_id))
        else:
            spot_info = line.split()
            spots[spot_id].add_state(SunspotState(time=itm.Time(str=spot_info[0].replace('_', ' ')),
                                                  wh_area=float(spot_info[1]), carrington=float(spot_info[2]),
                                                  lat=float(spot_info[3]), stonyhurst=float(spot_info[4]),
                                                  spot_id=spot_id))
    return spots


n_dim = 3  # dim of vector space
n_clusters = 10  # number of clusters for pre-processing clusterization
n_neighbours = 5  # number of nearest neighbours
min_area = 120.0  # min area to consider spot in measuring error (does not affect prediction)


def set_dim(new_n_dim):
    """

    sets new value of n_dim
    :param new_n_dim: new parameter value
    """
    global n_dim
    n_dim = new_n_dim


def set_neighbours(new_n_neighbours):
    """

    sets new value of n_neighbours
    :param new_n_neighbours: new parameter value
    """
    global n_neighbours
    n_neighbours = new_n_neighbours


def set_clusters(new_n_clusters):
    """

    sets new value of n_clusters
    :param new_n_clusters: new parameter value
    """
    global n_clusters
    n_clusters = new_n_clusters


def set_min_area(new_min_area):
    """

    sets new value of min_area
    :param new_min_area: new parameter value
    """
    global min_area
    min_area = new_min_area


class PredictionLinker:
    """

    links vector with the spot
    """

    def __init__(self, vec, spot_id, prediction):
        self.vec = vec
        self.id = spot_id
        self.prd = prediction


class NeighbourInfo:
    """

    info for vector - candidate to nearest neighbour
    """

    def __init__(self, neighbour_dist, neighbour_id, prediction):
        self.dist = neighbour_dist
        self.id = neighbour_id
        self.prd = prediction


def clusterize_data(spots):
    """

    creates vectors from spots, clusterizes vectors and generates fitting and testing samples
    :param spots: a dict of spots (mapping spot_id => Sunspot)
    :return: k_means, clusters, sample

    - k_means sklearn clusters object (necessary for further vector predicting)
    - clusters clusterized fitting sample
    - sample testing sample
    """
    vector_space = list()
    mapping_table = list()
    sample = list()
    for spot in spots.values():
        for i in range(spot.lifetime - n_dim + 1):
            vec_valid = True
            for j in range(n_dim):
                if spot.states[i + j] is None:
                    vec_valid = False
                    break
            if not vec_valid:
                continue
            if not is_in_interval(spot.states[i], -60, 60):
                continue

            if i == spot.lifetime - n_dim:
                if not is_in_interval(spot.states[spot.lifetime - 1], -60, 60):
                    continue
                if flip(0.5):
                    vector_space.append([spot.states[j].wh_area for j in range(i, i + n_dim)])
                    mapping_table.append((spot.id, 0))
                else:
                    vec = [spot.states[j].wh_area for j in range(i, i + n_dim)]
                    sample.append(PredictionLinker(vec, spot.id, 0))
                continue

            if spot.states[i + n_dim] is None or not is_in_interval(spot.states[i + n_dim], -60, 60):
                continue
            if flip(0.5):
                vector_space.append([spot.states[j].wh_area for j in range(i, i + n_dim)])
                mapping_table.append((spot.id, spot.states[i + n_dim].wh_area))
            else:
                vec = [spot.states[j].wh_area for j in range(i, i + n_dim)]
                sample.append(PredictionLinker(vec, spot.id, spot.states[i + n_dim].wh_area))

    k_means = cls.KMeans(n_clusters=n_clusters).fit(vector_space)
    clusters = list([] for i in range(n_clusters))
    for i in range(len(k_means.labels_)):
        clusters[k_means.labels_[i]].append(
            PredictionLinker(vector_space[i], mapping_table[i][0], mapping_table[i][1]))
    return k_means, clusters, sample


def is_in_interval(spot_state, left, right):
    """

    check whether given SunspotState.stonyhurst fits degrees interval
    :param spot_state: SunspotState class exemplar
    :param left: interval left border
    :param right: interval right border
    :return:
    """
    if left < spot_state.stonyhurst < right:
        return True
    return False


def dist(v1, v2):
    """

    :param v1: first vector
    :param v2: second vector
    :return: Euclid metrics distance
    """
    return np.linalg.norm(np.array(v1) - np.array(v2))


def generate_vector(target_spot, day):
    """

    generates vector from given Sunspot and given day
    unknown spot areas are replaced by following day areas (a kind of const regression)
    :param target_spot: Sunspot class exemplar
    :param day: last day of observation to generate vector
    :return: generated vector
    """
    vec = [0] * n_dim
    i = 0
    while i < n_dim and i <= day and target_spot.states[day - i] is not None:
        vec[n_dim - 1 - i] = target_spot.states[day - i].wh_area
        i += 1
    while i < n_dim:
        vec[n_dim - 1 - i] = vec[n_dim - i]
        i += 1
    return vec


def closest_spots(spot_id, vec, k_means, clusters):
    """

    finds closest neighbours to given vector
    :param spot_id: spot identifier (to avoid the spot predicting itself)
    :param vec: vector to find neighbours
    :param k_means: sklearn clusters object
    :param clusters: clusterized fitting sample
    :return: a list with nearest neighbours info
    """
    cluster_id = k_means.predict([vec])[0]
    res = list()
    for linker in clusters[cluster_id]:
        if linker.id == spot_id:
            continue
        neighbour_dist = dist(vec, linker.vec)
        if len(res) < n_neighbours:
            res.append(NeighbourInfo(neighbour_dist, linker.id, linker.prd))
            if len(res) == n_neighbours:
                res = sorted(res, key=lambda obj: obj.dist)
        else:
            for i in range(n_neighbours):
                if neighbour_dist < res[i].dist:
                    for j in range(n_neighbours - 1, i, -1):
                        res[j] = res[j - 1]
                    res[i] = NeighbourInfo(neighbour_dist, linker.id, linker.prd)
                    break
    return res


def predict_area_mean(spot_id, vec, k_means, clusters):
    """

    predicts area - mean area of neighbours
    :param spot_id: target spot identifier
    :param vec: generated vector
    :param k_means: k_means: sklearn clusters object
    :param clusters: clusterized fitting sample
    :return: predicted area
    """
    cls_spots = closest_spots(spot_id, vec, k_means, clusters)
    res = sum(neighbour.prd for neighbour in cls_spots)
    if len(cls_spots) > 0:
        res /= len(cls_spots)
    return res


def predict_area_weighted(spot_id, vec, k_means, clusters):
    """

    predicts area - weighted mean area of neighbours
    :param spot_id: target spot identifier
    :param vec: generated vector
    :param k_means: sklearn clusters object
    :param clusters: clusterized fitting sample
    :return: predicted area
    """
    cls_spots = closest_spots(spot_id, vec, k_means, clusters)
    res = 0
    eps = 0.001
    if len(cls_spots) > 0:
        norm = 1 / (sum(1 / (neighbour.dist + eps) for neighbour in cls_spots))
    for neighbour in cls_spots:
        coef = norm / (neighbour.dist + eps)
        res += coef * neighbour.prd
    return res


def predict_area_naive(vec, decrease):
    """

    predicts area - decreases last known area by decrease rate
    :param vec: generated vector
    :param decrease: a rate to decrease vector
    :return: predicted area
    """
    return decrease * vec[len(vec) - 1]


def predict_area(spot_id, vec, mode='mean', k_means=None, clusters=None, decrease=None):
    """

    predicts area with specified method
    :param spot_id: target spot identifier
    :param vec: generated vector
    :param mode: prediction mode ('mean', 'weighted' or 'naive')
    :param k_means: sklearn clusters object
    :param clusters: clusterized fitting sample
    :param decrease: a rate to decrease vector (naive only)
    :return: predicted area
    """
    if mode == 'mean':
        return predict_area_mean(spot_id, vec, k_means, clusters)
    if mode == 'weighted':
        return predict_area_weighted(spot_id, vec, k_means, clusters)
    if mode == 'naive':
        return predict_area_naive(vec, decrease)


def generate_sample(spots, size):
    """

    generates random sample
    :param spots: a dict of spots (mapping spot_id => Sunspot)
    :param size: sample size
    :return: sample
    """
    result = list()
    i = 0
    while i < size:
        rand_id = rand.choice(list(spots.keys()))
        spot = spots[rand_id]
        if spot.lifetime < n_dim + 1:
            continue
        rand_day = rand.randrange(n_dim - 1, spot.lifetime - 1)
        if spot.states[rand_day] is None or spot.states[rand_day + 1] is None:
            continue
        result.append(PredictionLinker(generate_vector(spot, rand_day), spot.id, spot.states[rand_day + 1].wh_area))
        i += 1
    return result


def predict_sample(sample, mode='mean', k_means=None, clusters=None, decrease=None):
    """

    predicts area for spots from sample
    :param sample: sample to predict
    :param mode: prediction mode ('mean', 'weighted' or 'naive')
    :param k_means: sklearn clusters object
    :param clusters: clusterized fitting sample
    :param decrease: a rate to decrease vector (naive only)
    :return: list of predictions
    """
    return list(predict_area(linker.id, linker.vec, mode, k_means, clusters, decrease) for linker in sample)


def error_distribution(sample, prediction):
    """

    calculates relative errors for prediction
    :param sample: sample that was predicted
    :param prediction: a list of predictions
    :return: list of relative errors
    """
    errors = list()
    i = 0
    for linker in sample:
        if linker.vec[len(linker.vec) - 1] > min_area and linker.prd > min_area:
            errors.append(prediction[i] / linker.prd - 1)
        i += 1
    return errors


def lifetime_distribution(spots, max_lifetime=100, center_spots=False, center_rate=2 / 3, eps=0.001):
    """

    calculates spots lifetime distribution
    :param spots: a dict of spots (mapping spot_id => Sunspot)
    :param max_lifetime: max allowed lifetime
    :param center_spots: is True only center spots are considered
    :param center_rate: longtitude rate of center
    :param eps: allowable error to cut tail
    :return: a list of lifetime distribution
    (1 day - list[0], 2 days - list[1], ...)
    """
    lifetime = [0] * max_lifetime
    for spot in spots.values():
        if spot.lifetime < max_lifetime and \
                (not center_spots or is_in_interval(spot.states[0], -center_rate * 90, center_rate * 90)):
            lifetime[spot.lifetime - 1] += 1
    coef = 1 / sum(lifetime)
    lifetime = list(val * coef for val in lifetime)
    while lifetime[len(lifetime) - 1] < eps:
        lifetime.pop()
    return lifetime


decrease_rate = 1 / 3  # a rate of sudden decrease
decrease_prb = 2 / 7  # a probability of sudden decrease
disappear_area = 20.0  # min area to consider sunspot disappeared


def set_decrease_rate(new_decrease_rate):
    """

    sets new value of decrease_rate
    :param new_decrease_rate: new parameter value
    """
    global decrease_rate
    decrease_rate = new_decrease_rate


def set_decrease_prb(new_decrease_prb):
    """

    sets new value of decrease_prb
    :param new_decrease_prb: new parameter value
    """
    global decrease_prb
    decrease_prb = new_decrease_prb


def set_disappear_area(new_disappear_area):
    """

    sets new value of disappear_area
    :param new_disappear_area: new parameter value
    """
    global disappear_area
    disappear_area = new_disappear_area


def set_params(new_n_dim=n_dim, new_n_clusters=n_clusters, new_n_neighbours=n_neighbours, new_min_area=min_area,
               new_decrease_rate=decrease_rate, new_decrease_prb=decrease_prb, new_disappear_area=disappear_area):
    """

    sets new parameter values
    """
    set_dim(new_n_dim)
    set_clusters(new_n_clusters)
    set_neighbours(new_n_neighbours)
    set_min_area(new_min_area)
    set_decrease_rate(new_decrease_rate)
    set_decrease_prb(new_decrease_prb)
    set_disappear_area(new_disappear_area)


def flip(prb):
    """

    returns True with prb probability
    :param prb: probability
    :return: True or False
    """
    if rand.random() < prb:
        return True
    return False


def life_prediction(spot, mode='mean', k_means=None, clusters=None, decrease=None, sudden_decrease=False):
    """

    predicts full history for Sunspot
    :param spot: Sunspot class exemplar
    :param mode: prediction mode ('mean', 'weighted' or 'naive')
    :param k_means: sklearn clusters object
    :param clusters: clusterized fitting sample
    :param decrease: a rate to decrease vector (naive only)
    :param sudden_decrease: True to allow sudden decrease event
    :return: new Sunspot with corrected history
    """
    spot_copy = copy.deepcopy(spot)
    for i in range(spot_copy.lifetime):
        if spot_copy.states[i] is None:
            area = predict_area(spot_copy, generate_vector(spot_copy, i - 1), mode,
                                k_means, clusters, decrease)
            obs_time = copy.deepcopy(spot_copy.states[i - 1].time)
            obs_time.next_day()
            spot_copy.states[i] = SunspotState(time=obs_time, wh_area=area,
                                               carrington=spot_copy.states[i - 1].carrington,
                                               lat=spot_copy.states[i - 1].lat,
                                               stonyhurst=spot_copy.states[i - 1].stonyhurst,
                                               simulated=True, spot_id=spot.id)
    if not is_in_interval(spot.states[spot.lifetime - 1], 90 - 180 / 14 * 2, 90):
        return spot_copy
    area = spot.states[spot.lifetime - 1].wh_area
    while area > disappear_area:
        if sudden_decrease and flip(decrease_prb):
            area = decrease_rate * area
        else:
            area = predict_area(spot_copy, generate_vector(spot_copy, spot_copy.lifetime - 1), mode,
                                k_means, clusters, decrease)
        if area < 1.0:
            break
        obs_time = copy.deepcopy(spot_copy.states[spot_copy.lifetime - 1].time)
        obs_time.next_day()
        spot_copy.add_state(SunspotState(time=obs_time, wh_area=area,
                                         carrington=spot.states[spot.lifetime - 1].carrington,
                                         lat=spot.states[spot.lifetime - 1].lat,
                                         stonyhurst=spot.states[spot.lifetime - 1].stonyhurst,
                                         simulated=True, spot_id=spot.id))
    return spot_copy


def correct_database(spots, print_state=False, mode='mean',
                     k_means=None, clusters=None, decrease=None, sudden_decrease=False):
    """

    predicts full storied for Sunspots in spots
    :param spots: a dict of spots (mapping spot_id => Sunspot)
    :param print_state: True if print processing state)
    :param mode: prediction mode ('mean', 'weighted' or 'naive')
    :param k_means: sklearn clusters object
    :param clusters: clusterized fitting sample
    :param decrease: a rate to decrease vector (naive only)
    :param sudden_decrease: True to allow sudden decrease event
    :return: new corrected dict of spots
    """
    corrected_spots = dict()
    warnings.filterwarnings('ignore')
    i = 0
    for spot in spots.values():
        corrected_spots[spot.id] = life_prediction(spot, mode, k_means, clusters, decrease, sudden_decrease)
        i += 1
        if i % 100 == 0 and print_state:
            print(i)
    return corrected_spots


def create_database(filename, corrected_spots):
    """

    creates new corrected database
    :param filename: a file to store the database
    :param corrected_spots: a dict of spots (mapping spot_id => Sunspot)
    """
    file = open(filename, 'w')
    for spot in corrected_spots.values():
        for state in spot.states:
            file.write(str(state) + '\n')
    file.close()


def exponent_approximation(data, X, A, B):
    """

    calculate best MSE exponent approximation (exp(a * x + b))
    :param data: data values
    :param X: arguments
    :param A: range for a values
    :param B: range for b values
    :return: a, b coefficients
    """
    a_min = None
    b_min = None
    min_penalty = None
    for a in A:
        for b in B:
            penalty = 0
            for i in range(len(X)):
                penalty += (np.log(data[i]) - (a * (X[i] + 1) + b)) ** 2
            if min_penalty is None or min_penalty > penalty:
                a_min = a
                b_min = b
                min_penalty = penalty
    return a_min, b_min
